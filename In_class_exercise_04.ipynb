{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DurgaBhavana/5731Submissions/blob/master/In_class_exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EuX00KHNeSpw"
      },
      "source": [
        "# **The fourth in-class-exercise (20 points in total)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s-vTOb03hG1f"
      },
      "source": [
        "# 1. Text Data Preprocessing\n",
        "\n",
        "Here is a [legal case](https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "## 1.1 Basic feature extraction using text data (4 points)\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "## 1.2 Basic Text Pre-processing of text data (4 points)\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "## 1.3 Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above. (4 points)\n",
        "\n",
        "\n",
        "## 1.4 Advance Text Processing (Extra credit: 4 points)\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAy-XRvVWeF5",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Basic feature extraction using text data (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vR0L3_CreM_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "99cbd60b-e5fd-4532-e56e-ee21e525646c"
      },
      "source": [
        "# Import the required libraries\n",
        "import pandas as pd\n",
        "from six.moves import urllib\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import itertools\n",
        "import collections\n",
        "from nltk import ngrams"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dArkFLRc20mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading text from the url\n",
        "legal_case = \"https://raw.githubusercontent.com/unt-iialab/INFO5731_FALL2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\"\n",
        "sample_text = []\n",
        "file_data = urllib.request.urlopen(legal_case)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbpbQKCG24k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoding the text\n",
        "for element in file_data:\n",
        "    sample_text.append(element.decode(\"utf-8\").replace('\\r\\n', ''))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DZQw43I26or",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "89c4225d-e624-4870-8460-de1a9364f255"
      },
      "source": [
        "# Read the decoded text into a data frame\n",
        "data_df = pd.DataFrame (sample_text, columns = ['Decoded Data'])\n",
        "data_df"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoded Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADAMS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Negative Treatment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Decoded Data\n",
              "0                                                     \n",
              "1                                           5 Ala. 740\n",
              "2                            Supreme Court of Alabama.\n",
              "3                                                ADAMS\n",
              "4                                                   v.\n",
              "..                                                 ...\n",
              "154            There are no Filings for this citation.\n",
              "155                                 Negative Treatment\n",
              "156  There are no Negative Treatment results for th...\n",
              "157                                            History\n",
              "158    There are no History results for this citation.\n",
              "\n",
              "[159 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMj7l1xH36JU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "05f62503-a3db-4670-8645-e5c3fe440690"
      },
      "source": [
        "data_df['sentences'] = data_df['Decoded Data'].apply(lambda text_processing: len(str(text_processing).split(\".\")))   # Number of sentences (split by '.')\n",
        "data_df['words'] = data_df['Decoded Data'].apply(lambda text_processing: len(str(text_processing).split(\" \")))   # Number of sentences (split by ' ')\n",
        "data_df['characters'] = data_df['Decoded Data'].str.len()   # Number of characters \n",
        "data_df"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoded Data</th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>characters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Negative Treatment</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>History</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Decoded Data  ...  characters\n",
              "0                                                       ...           0\n",
              "1                                           5 Ala. 740  ...          10\n",
              "2                            Supreme Court of Alabama.  ...          25\n",
              "3                                                ADAMS  ...           5\n",
              "4                                                   v.  ...           2\n",
              "..                                                 ...  ...         ...\n",
              "154            There are no Filings for this citation.  ...          39\n",
              "155                                 Negative Treatment  ...          18\n",
              "156  There are no Negative Treatment results for th...  ...          58\n",
              "157                                            History  ...           7\n",
              "158    There are no History results for this citation.  ...          47\n",
              "\n",
              "[159 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYjPaWsm4HTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b4d17823-d3c2-4f5c-fef2-73c91d4134b5"
      },
      "source": [
        "# Average word length\n",
        "def average_word(read_sentence):\n",
        "  if len(read_sentence.split()) != 0:\n",
        "    word_length = sum(len(text) for text in read_sentence.split())/len(read_sentence.split())\n",
        "    return word_length\n",
        "  else:\n",
        "    return None\n",
        "data_df['Average word length'] = data_df['Decoded Data'].apply(lambda text_processing: average_word(text_processing))\n",
        "data_df"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoded Data</th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>characters</th>\n",
              "      <th>Average word length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>39</td>\n",
              "      <td>4.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Negative Treatment</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>8.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>5.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>History</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>47</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Decoded Data  ...  Average word length\n",
              "0                                                       ...                  NaN\n",
              "1                                           5 Ala. 740  ...             2.666667\n",
              "2                            Supreme Court of Alabama.  ...             5.500000\n",
              "3                                                ADAMS  ...             5.000000\n",
              "4                                                   v.  ...             2.000000\n",
              "..                                                 ...  ...                  ...\n",
              "154            There are no Filings for this citation.  ...             4.714286\n",
              "155                                 Negative Treatment  ...             8.500000\n",
              "156  There are no Negative Treatment results for th...  ...             5.555556\n",
              "157                                            History  ...             7.000000\n",
              "158    There are no History results for this citation.  ...             5.000000\n",
              "\n",
              "[159 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv65CIHV7m6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "85d62a46-40e0-464b-c8b8-602e2b83a1e8"
      },
      "source": [
        "# Number of stopwords\n",
        "stop_word = stopwords.words('english')\n",
        "data_df['stopwords'] = data_df['Decoded Data'].apply(lambda x: len([x for x in x.split() if x in stop_word]))\n",
        "# Number of special characters\n",
        "def no_of_special_characters(read_sentence):\n",
        "  special_character_count = 0\n",
        "  range_search = range(len(read_sentence))\n",
        "  for element in range_search:\n",
        "    if not((read_sentence[element].isalpha()) and (read_sentence[element].isdigit())):\n",
        "        special_character_count = special_character_count + 1\n",
        "  return special_character_count\n",
        "data_df['Number of special characters'] = data_df['Decoded Data'].apply(lambda x: special_characters(x))\n",
        "# Number of numerics\n",
        "data_df['numerics'] = data_df['Decoded Data'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "# Number of uppercase words\n",
        "data_df['Upper case words'] = data_df['Decoded Data'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
        "data_df"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoded Data</th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>characters</th>\n",
              "      <th>Average word length</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>Number of special characters</th>\n",
              "      <th>numerics</th>\n",
              "      <th>Upper case words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>39</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Negative Treatment</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>History</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>47</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Decoded Data  ...  Upper case words\n",
              "0                                                       ...                 0\n",
              "1                                           5 Ala. 740  ...                 0\n",
              "2                            Supreme Court of Alabama.  ...                 0\n",
              "3                                                ADAMS  ...                 1\n",
              "4                                                   v.  ...                 0\n",
              "..                                                 ...  ...               ...\n",
              "154            There are no Filings for this citation.  ...                 0\n",
              "155                                 Negative Treatment  ...                 0\n",
              "156  There are no Negative Treatment results for th...  ...                 0\n",
              "157                                            History  ...                 0\n",
              "158    There are no History results for this citation.  ...                 0\n",
              "\n",
              "[159 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srxny8a_WstF",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Basic Text Pre-processing of text data (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H43aWxaMWvcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1b742f46-a8da-4d9a-e77f-629972252b31"
      },
      "source": [
        "# Lower Casing\n",
        "data_df['Lower casing'] = data_df['Decoded Data'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "# Punctuation removal\n",
        "data_df['Punctuation removal'] = data_df['Lower casing'].str.replace('[^\\w\\s]','')\n",
        "# Stopwords removal\n",
        "stop_word = stopwords.words('english')\n",
        "data_df['Stopwords removal'] = data_df['Punctuation removal'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_word))\n",
        "# Frequent words removal\n",
        "frequent_words = pd.Series(' '.join(data_df['Stopwords removal']).split())\n",
        "frequent_words_removal = frequent_words.value_counts()[:10]\n",
        "print(frequent_words_removal)\n",
        "list_of_frequent_words = list(frequent_words_removal.index)\n",
        "data_df['Updated - no frequent words'] = data_df['Stopwords removal'].apply(lambda x: \" \".join(x for x in x.split() if x not in list_of_frequent_words))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "execution    50\n",
            "crop         49\n",
            "levy         25\n",
            "lien         25\n",
            "v            22\n",
            "claimants    22\n",
            "case         21\n",
            "right        21\n",
            "court        20\n",
            "gathered     19\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXzyoQA2Wvpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "4d80611f-1b69-4cc6-fba2-ae5b79eb7696"
      },
      "source": [
        "# Rare words removal\n",
        "rare_words = pd.Series(' '.join(data_df['Stopwords removal']).split())\n",
        "rare_words_removal = rare_words.value_counts()[-10:]\n",
        "print(rare_words_removal)\n",
        "indexed = rare_words_removal.index\n",
        "list_of_rare_words = list(indexed)\n",
        "data_df['Updated - no rare words'] = data_df['Updated - no frequent words'].apply(lambda x: \" \".join(x for x in x.split() if x not in list_of_rare_words))\n",
        "data_df"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chitty           1\n",
            "693              1\n",
            "declares         1\n",
            "elliott          1\n",
            "subjectmatter    1\n",
            "slaves           1\n",
            "sealed           1\n",
            "policy           1\n",
            "424              1\n",
            "agreed           1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoded Data</th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>characters</th>\n",
              "      <th>Average word length</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>Number of special characters</th>\n",
              "      <th>numerics</th>\n",
              "      <th>Upper case words</th>\n",
              "      <th>Lower casing</th>\n",
              "      <th>Punctuation removal</th>\n",
              "      <th>Stopwords removal</th>\n",
              "      <th>Updated - no frequent words</th>\n",
              "      <th>Updated - no rare words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5 ala. 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>supreme court of alabama.</td>\n",
              "      <td>supreme court of alabama</td>\n",
              "      <td>supreme court alabama</td>\n",
              "      <td>supreme alabama</td>\n",
              "      <td>supreme alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v.</td>\n",
              "      <td>v</td>\n",
              "      <td>v</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>39</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there are no filings for this citation.</td>\n",
              "      <td>there are no filings for this citation</td>\n",
              "      <td>filings citation</td>\n",
              "      <td>filings citation</td>\n",
              "      <td>filings citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Negative Treatment</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there are no negative treatment results for th...</td>\n",
              "      <td>there are no negative treatment results for th...</td>\n",
              "      <td>negative treatment results citation</td>\n",
              "      <td>negative treatment results citation</td>\n",
              "      <td>negative treatment results citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>History</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>47</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there are no history results for this citation.</td>\n",
              "      <td>there are no history results for this citation</td>\n",
              "      <td>history results citation</td>\n",
              "      <td>history results citation</td>\n",
              "      <td>history results citation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Decoded Data  ...              Updated - no rare words\n",
              "0                                                       ...                                     \n",
              "1                                           5 Ala. 740  ...                            5 ala 740\n",
              "2                            Supreme Court of Alabama.  ...                      supreme alabama\n",
              "3                                                ADAMS  ...                                adams\n",
              "4                                                   v.  ...                                     \n",
              "..                                                 ...  ...                                  ...\n",
              "154            There are no Filings for this citation.  ...                     filings citation\n",
              "155                                 Negative Treatment  ...                   negative treatment\n",
              "156  There are no Negative Treatment results for th...  ...  negative treatment results citation\n",
              "157                                            History  ...                              history\n",
              "158    There are no History results for this citation.  ...             history results citation\n",
              "\n",
              "[159 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo7WVRiVWvUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "1a31b47d-f910-4628-c173-5fd2c900671e"
      },
      "source": [
        "# Spelling correction\n",
        "data_df['Spelling correction'] = data_df['Updated - no rare words'].apply(lambda x: str(TextBlob(x).correct()))\n",
        "# Tokenization\n",
        "data_df['Tokenization'] = data_df['Spelling correction'].apply(lambda x: TextBlob(x).words)\n",
        "# Stemming\n",
        "st = PorterStemmer()\n",
        "data_df['Stemming'] = data_df['Tokenization'].apply(lambda x: \" \".join([st.stem(word) for word in x]))\n",
        "# Lemmatization\n",
        "data_df['Lemmatization'] = data_df['Stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "data_df"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Decoded Data</th>\n",
              "      <th>sentences</th>\n",
              "      <th>words</th>\n",
              "      <th>characters</th>\n",
              "      <th>Average word length</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>Number of special characters</th>\n",
              "      <th>numerics</th>\n",
              "      <th>Upper case words</th>\n",
              "      <th>Lower casing</th>\n",
              "      <th>Punctuation removal</th>\n",
              "      <th>Stopwords removal</th>\n",
              "      <th>Updated - no frequent words</th>\n",
              "      <th>Updated - no rare words</th>\n",
              "      <th>Spelling correction</th>\n",
              "      <th>Tokenization</th>\n",
              "      <th>Stemming</th>\n",
              "      <th>Lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5 ala. 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 ala 740</td>\n",
              "      <td>5 all 740</td>\n",
              "      <td>[5, all, 740]</td>\n",
              "      <td>5 all 740</td>\n",
              "      <td>5 all 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>supreme court of alabama.</td>\n",
              "      <td>supreme court of alabama</td>\n",
              "      <td>supreme court alabama</td>\n",
              "      <td>supreme alabama</td>\n",
              "      <td>supreme alabama</td>\n",
              "      <td>supreme alabama</td>\n",
              "      <td>[supreme, alabama]</td>\n",
              "      <td>suprem alabama</td>\n",
              "      <td>suprem alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>adams</td>\n",
              "      <td>[adams]</td>\n",
              "      <td>adam</td>\n",
              "      <td>adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>v.</td>\n",
              "      <td>v</td>\n",
              "      <td>v</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>There are no Filings for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>39</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>4</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there are no filings for this citation.</td>\n",
              "      <td>there are no filings for this citation</td>\n",
              "      <td>filings citation</td>\n",
              "      <td>filings citation</td>\n",
              "      <td>filings citation</td>\n",
              "      <td>filing situation</td>\n",
              "      <td>[filing, situation]</td>\n",
              "      <td>file situat</td>\n",
              "      <td>file situat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>Negative Treatment</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>negative treatment</td>\n",
              "      <td>[negative, treatment]</td>\n",
              "      <td>neg treatment</td>\n",
              "      <td>neg treatment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>There are no Negative Treatment results for th...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there are no negative treatment results for th...</td>\n",
              "      <td>there are no negative treatment results for th...</td>\n",
              "      <td>negative treatment results citation</td>\n",
              "      <td>negative treatment results citation</td>\n",
              "      <td>negative treatment results citation</td>\n",
              "      <td>negative treatment results situation</td>\n",
              "      <td>[negative, treatment, results, situation]</td>\n",
              "      <td>neg treatment result situat</td>\n",
              "      <td>neg treatment result situat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>History</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>history</td>\n",
              "      <td>[history]</td>\n",
              "      <td>histori</td>\n",
              "      <td>histori</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>There are no History results for this citation.</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>47</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>there are no history results for this citation.</td>\n",
              "      <td>there are no history results for this citation</td>\n",
              "      <td>history results citation</td>\n",
              "      <td>history results citation</td>\n",
              "      <td>history results citation</td>\n",
              "      <td>history results situation</td>\n",
              "      <td>[history, results, situation]</td>\n",
              "      <td>histori result situat</td>\n",
              "      <td>histori result situat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Decoded Data  ...                Lemmatization\n",
              "0                                                       ...                             \n",
              "1                                           5 Ala. 740  ...                    5 all 740\n",
              "2                            Supreme Court of Alabama.  ...               suprem alabama\n",
              "3                                                ADAMS  ...                         adam\n",
              "4                                                   v.  ...                             \n",
              "..                                                 ...  ...                          ...\n",
              "154            There are no Filings for this citation.  ...                  file situat\n",
              "155                                 Negative Treatment  ...                neg treatment\n",
              "156  There are no Negative Treatment results for th...  ...  neg treatment result situat\n",
              "157                                            History  ...                      histori\n",
              "158    There are no History results for this citation.  ...        histori result situat\n",
              "\n",
              "[159 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arXiqIcFc5Dr",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Save all the clean sentences to a csv file (one column, each raw is a sentence) after finishing all the steps above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZmXgHYsc_Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = data_df.to_csv('CleanedSentences.csv',index=False)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_WIqqjgdSbn",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Advance Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-hth3Z_dU9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "97434b5e-6c5b-4c87-df63-4cbade9bd470"
      },
      "source": [
        "#term frequencies\n",
        "tf = (data_df['Lemmatization']).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
        "tf.columns = ['word','Term requencies']\n",
        "tf"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>Term requencies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>740</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>alabama</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>rye</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>yield</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>file</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>neg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>histori</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>706 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  Term requencies\n",
              "0                        35.0\n",
              "1        all             17.0\n",
              "2        740              2.0\n",
              "3          5              8.0\n",
              "4    alabama              1.0\n",
              "..       ...              ...\n",
              "701      rye              1.0\n",
              "702    yield              1.0\n",
              "703     file              2.0\n",
              "704      neg              2.0\n",
              "705  histori              2.0\n",
              "\n",
              "[706 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbMJ69bOilMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_words = []\n",
        "for i in data_df['Lemmatization']:\n",
        "  list_of_words.append(nltk.tokenize.word_tokenize(i))\n",
        "words = [i for i in list_of_words if i != []]\n",
        "looping = list(itertools.chain.from_iterable(words))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKqUIW29j5C3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "777073d6-2400-4c57-ee7c-fa4dc180c35a"
      },
      "source": [
        "# top 10 one grams\n",
        "one = ngrams(looping, 1)\n",
        "collections.Counter(one).most_common(10)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('law',), 18),\n",
              " (('all',), 17),\n",
              " (('grow',), 17),\n",
              " (('contract',), 16),\n",
              " (('rep',), 16),\n",
              " (('plaintiff',), 15),\n",
              " (('posse',), 14),\n",
              " (('attach',), 14),\n",
              " (('cotton',), 14),\n",
              " (('2',), 13)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wucu0DtHkM3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "26579a69-fddd-4229-d078-58fdd50cc8ce"
      },
      "source": [
        "# top 10 bigrams\n",
        "fd = nltk.FreqDist(nltk.bigrams(looping))\n",
        "fd.most_common(10)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('common', 'law'), 7),\n",
              " (('john', 'rep'), 6),\n",
              " (('tri', 'hon'), 6),\n",
              " (('fieri', 'facial'), 5),\n",
              " (('while', 'foot'), 4),\n",
              " (('can', 'not'), 4),\n",
              " (('appeal', 'circuit'), 4),\n",
              " (('error', 'circuit'), 3),\n",
              " (('attach', 'favor'), 3),\n",
              " (('allen', 'harrison'), 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMh2jV39kPjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "3405370d-5c19-4ddd-cc94-2043d43a4336"
      },
      "source": [
        "# top 10 trigrams\n",
        "fd = nltk.FreqDist(nltk.trigrams(looping))\n",
        "fd.most_common(10)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('2', 'john', 'rep'), 3),\n",
              " (('all', 'grover', 'convers'), 3),\n",
              " (('5', 'all', '740'), 2),\n",
              " (('writ', 'error', 'circuit'), 2),\n",
              " (('interest', 'vest', 'posse'), 2),\n",
              " (('vest', 'posse', 'either'), 2),\n",
              " (('posse', 'either', 'immedi'), 2),\n",
              " (('either', 'immedi', 'futur'), 2),\n",
              " (('immedi', 'futur', 'time'), 2),\n",
              " (('case', 'cite', 'headnot'), 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BBiC4E_kefvV"
      },
      "source": [
        "# 2. Python Regular Expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjixzocWeZbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z1QJ-UwCenvN"
      },
      "source": [
        "## 2.1 Write a Python program to remove leading zeros from an IP address. (4 points)\n",
        "\n",
        "ip = \"260.08.094.109\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSv6fVhOfFmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "844681a5-794d-4e05-a19d-c5ee10041955"
      },
      "source": [
        "ip = \"260.08.094.109\"\n",
        "re.sub('\\.[0]*', '.', ip)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'260.8.94.109'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXRjaHzrfKAy"
      },
      "source": [
        "## 2.2 Write a Python Program to extract all the years from the following sentence. (4 points)\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7xdJpDx9gjbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0cfc9d7-eb7d-4c2a-d3e3-67a39cc0dfa5"
      },
      "source": [
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\"\n",
        "re.findall(r'2\\d\\d\\d', sentence)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2010', '2010', '2019']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    }
  ]
}