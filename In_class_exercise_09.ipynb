{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DurgaBhavana/5731Submissions/blob/master/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9PnFDdSJbC9"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG4eGzRHJbC_"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a5dWryxNFHb",
        "outputId": "85c11f00-4af9-4fa4-dfd8-b3bec2cf32c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, svm\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7hyzwGK1_97"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfTENqhqkzE_"
      },
      "source": [
        "def reading_data(file_path):\n",
        "  text_data, sentiments = [], []\n",
        "  file_data = open(file_path).read()\n",
        "  for i, j in enumerate(file_data.split(\"\\n\")):\n",
        "    after_split = j.split(' ')\n",
        "    text_data.append(\" \".join(after_split[1:]))\n",
        "    sentiments.append(after_split[0])\n",
        "  return text_data, sentiments"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlvKFYV5JbDA"
      },
      "source": [
        "training_text_data, training_sentiments = reading_data('/content/stsa-train.txt')\n",
        "training_df = pd.DataFrame(list(zip(training_sentiments, training_text_data)), columns = ['Sentimental Value', 'Raw Data'])\n",
        "testing_text_data, testing_sentiments = reading_data('/content/stsa-test.txt')\n",
        "testing_df = pd.DataFrame(list(zip(testing_sentiments, testing_text_data)), columns = ['Sentimental Value', 'Raw Data'])"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oACY4OPQQW1"
      },
      "source": [
        "#Pre-processing\n",
        "# Special characters removal\n",
        "training_df['After noise removal'] = training_df['Raw Data'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "testing_df['After noise removal'] = testing_df['Raw Data'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "# Punctuation removal\n",
        "training_df['Punctuation removal'] = training_df['After noise removal'].str.replace('[^\\w\\s]','')\n",
        "testing_df['Punctuation removal'] = testing_df['After noise removal'].str.replace('[^\\w\\s]','')\n",
        "# Stopwords removal\n",
        "stop_word = stopwords.words('english')\n",
        "training_df['Stopwords removal'] = training_df['Punctuation removal'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_word))\n",
        "testing_df['Stopwords removal'] = testing_df['Punctuation removal'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_word))\n",
        "# Lower Casing\n",
        "training_df['Lower casing'] = training_df['Stopwords removal'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "testing_df['Lower casing'] = testing_df['Stopwords removal'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGldyW4AhYcX"
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(analyzer = 'word')\n",
        "tfidf_vector.fit(training_df['Lower casing'])\n",
        "x =  tfidf_vector.transform(training_df['Lower casing'])\n",
        "tfidf_vector_test = TfidfVectorizer(analyzer='word', vocabulary = tfidf_vector.vocabulary_)\n",
        "tfidf_vector_test.fit(testing_df['Lower casing'])\n",
        "test_values_x = tfidf_vector_test.transform(testing_df['Lower casing'])"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PFLm4SWrhpY"
      },
      "source": [
        "xtrain, xvalid, ytrain, yvalid = model_selection.train_test_split(x, training_df['Sentimental Value'],test_size=0.2)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbjLAj3Hsy1p"
      },
      "source": [
        "def csv(model, x_data, y_data):\n",
        "  scoring = 'accuracy'\n",
        "  kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "  return cross_val_score(model, x_data, y_data, cv=kfold).mean()"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV7jw_A3pEVL"
      },
      "source": [
        "def training_model(model_intializer):\n",
        "  model = model_intializer\n",
        "  model.fit(xtrain, ytrain)\n",
        "  predicted = model.predict(xvalid)\n",
        "  accuracy = accuracy_score(predicted, yvalid)\n",
        "  print(\"Accuracy of Traning data: {0}\".format(accuracy))\n",
        "  print(classification_report(yvalid, predicted))\n",
        "  predicted_testing = model.predict(test_values_x)\n",
        "  accuracy_testing = accuracy_score(predicted_testing, testing_df['Sentimental Value'])\n",
        "  print(\"Accuracy of Testing data: {0}\".format(accuracy_testing))\n",
        "  print(classification_report(testing_df['Sentimental Value'], predicted_testing))\n",
        "  if 'XGB' not in str(model):\n",
        "    print(\"Cross validation score obtained: {0}\".format(csv(model, test_values_x, testing_df['Sentimental Value'])))"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llqtYFulvHcD",
        "outputId": "721046bf-0f42-491a-fad4-e19d499a9d98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_model(naive_bayes.MultinomialNB())"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Traning data: 0.7927797833935019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.74      0.77       637\n",
            "           1       0.79      0.83      0.81       748\n",
            "\n",
            "    accuracy                           0.79      1385\n",
            "   macro avg       0.79      0.79      0.79      1385\n",
            "weighted avg       0.79      0.79      0.79      1385\n",
            "\n",
            "Accuracy of Testing data: 0.7925356750823271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.00      0.00      0.00         1\n",
            "           0       0.85      0.71      0.77       912\n",
            "           1       0.75      0.87      0.81       909\n",
            "\n",
            "    accuracy                           0.79      1822\n",
            "   macro avg       0.53      0.53      0.53      1822\n",
            "weighted avg       0.80      0.79      0.79      1822\n",
            "\n",
            "Cross validation score obtained: 0.7365309553834145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vf9blvOvbM1",
        "outputId": "992d674f-916e-4ff6-de09-2a711251c90e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_model(svm.SVC())"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Traning data: 0.7956678700361011\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.78       637\n",
            "           1       0.82      0.79      0.81       748\n",
            "\n",
            "    accuracy                           0.80      1385\n",
            "   macro avg       0.79      0.80      0.79      1385\n",
            "weighted avg       0.80      0.80      0.80      1385\n",
            "\n",
            "Accuracy of Testing data: 0.7886937431394072\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.00      0.00      0.00         1\n",
            "           0       0.81      0.75      0.78       912\n",
            "           1       0.77      0.83      0.80       909\n",
            "\n",
            "    accuracy                           0.79      1822\n",
            "   macro avg       0.53      0.53      0.53      1822\n",
            "weighted avg       0.79      0.79      0.79      1822\n",
            "\n",
            "Cross validation score obtained: 0.7217017954722873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqZp228HwT4I",
        "outputId": "23ee85b8-657d-44ba-ffbd-5513a97c2e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_model(KNeighborsClassifier(n_neighbors = 5))"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Traning data: 0.4996389891696751\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.71      0.57       637\n",
            "           1       0.57      0.32      0.41       748\n",
            "\n",
            "    accuracy                           0.50      1385\n",
            "   macro avg       0.52      0.52      0.49      1385\n",
            "weighted avg       0.52      0.50      0.48      1385\n",
            "\n",
            "Accuracy of Testing data: 0.5005488474204172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.00      0.00      0.00         1\n",
            "           0       0.50      0.71      0.59       912\n",
            "           1       0.50      0.29      0.37       909\n",
            "\n",
            "    accuracy                           0.50      1822\n",
            "   macro avg       0.33      0.33      0.32      1822\n",
            "weighted avg       0.50      0.50      0.48      1822\n",
            "\n",
            "Cross validation score obtained: 0.5005464480874318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUTpK7NRwkG-",
        "outputId": "ea511e2a-da52-4c35-99a3-305aea38390b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_model(DecisionTreeClassifier())"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Traning data: 0.6425992779783394\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.68      0.64       637\n",
            "           1       0.69      0.61      0.65       748\n",
            "\n",
            "    accuracy                           0.64      1385\n",
            "   macro avg       0.65      0.65      0.64      1385\n",
            "weighted avg       0.65      0.64      0.64      1385\n",
            "\n",
            "Accuracy of Testing data: 0.6761800219538968\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.00      0.00      0.00         1\n",
            "           0       0.67      0.68      0.68       912\n",
            "           1       0.68      0.67      0.67       909\n",
            "\n",
            "    accuracy                           0.68      1822\n",
            "   macro avg       0.45      0.45      0.45      1822\n",
            "weighted avg       0.68      0.68      0.68      1822\n",
            "\n",
            "Cross validation score obtained: 0.6031826097399866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyVEZaWMw3lU",
        "outputId": "3619e50a-4481-413f-d1cf-51b576836017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_model(RandomForestClassifier())"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Traning data: 0.7357400722021661\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.77      0.73       637\n",
            "           1       0.78      0.70      0.74       748\n",
            "\n",
            "    accuracy                           0.74      1385\n",
            "   macro avg       0.74      0.74      0.74      1385\n",
            "weighted avg       0.74      0.74      0.74      1385\n",
            "\n",
            "Accuracy of Testing data: 0.7420417124039517\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.00      0.00      0.00         1\n",
            "           0       0.73      0.76      0.75       912\n",
            "           1       0.75      0.72      0.74       909\n",
            "\n",
            "    accuracy                           0.74      1822\n",
            "   macro avg       0.49      0.49      0.49      1822\n",
            "weighted avg       0.74      0.74      0.74      1822\n",
            "\n",
            "Cross validation score obtained: 0.6575331772053084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCJ3MyiIxH2V",
        "outputId": "578b36fe-87ea-463a-aea9-c0ebb479940a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_model(XGBClassifier())\n",
        "scoring = 'accuracy'\n",
        "kfold = KFold(10, random_state = 7, shuffle=True)\n",
        "print(\"Cross validation score obtained: {0}\".format(cross_val_score(XGBClassifier(), test_values_x, testing_df['Sentimental Value']).mean()))"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Traning data: 0.6418772563176895\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.40      0.51       637\n",
            "           1       0.62      0.85      0.72       748\n",
            "\n",
            "    accuracy                           0.64      1385\n",
            "   macro avg       0.66      0.62      0.61      1385\n",
            "weighted avg       0.65      0.64      0.62      1385\n",
            "\n",
            "Accuracy of Testing data: 0.6487376509330406\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "                   0.00      0.00      0.00         1\n",
            "           0       0.75      0.45      0.56       912\n",
            "           1       0.60      0.85      0.71       909\n",
            "\n",
            "    accuracy                           0.65      1822\n",
            "   macro avg       0.45      0.43      0.42      1822\n",
            "weighted avg       0.68      0.65      0.63      1822\n",
            "\n",
            "Cross validation score obtained: 0.6059220231822973\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}