{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DurgaBhavana/5731Submissions/blob/master/In_class_exercise_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1OcLeGECBx5"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 10/29/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgioWZrICBx6"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTsxLVvYCBx6"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0_Uxf1vCBx7",
        "outputId": "d2257a83-c6a0-4a45-b902-3b5f6beb4456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/Abstracts for Sentiment Analysis.csv')\n",
        "df"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abstract 1</td>\n",
              "      <td>describe a method for statistical modeling bas...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abstract 2</td>\n",
              "      <td>Scaling conditional random fields for natural ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abstract 3</td>\n",
              "      <td>The paper addresses the issue of cooperation b...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abstract 4</td>\n",
              "      <td>In most natural language processing applicatio...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abstract 5</td>\n",
              "      <td>We propose a unified neural network architectu...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Abstract 96</td>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Abstract 97</td>\n",
              "      <td>Abstract—Natural Language Processing (NLP) is ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Abstract 98</td>\n",
              "      <td>ABSTRACT: After twenty years of disfavor, a te...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Abstract 99</td>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Abstract 100</td>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     document_id                                         clean_text sentiment\n",
              "0     Abstract 1  describe a method for statistical modeling bas...  Positive\n",
              "1     Abstract 2  Scaling conditional random fields for natural ...   Neutral\n",
              "2     Abstract 3  The paper addresses the issue of cooperation b...  Positive\n",
              "3     Abstract 4  In most natural language processing applicatio...  Positive\n",
              "4     Abstract 5  We propose a unified neural network architectu...  Positive\n",
              "..           ...                                                ...       ...\n",
              "95   Abstract 96  This paper presents a workbench built by Pribe...  Positive\n",
              "96   Abstract 97  Abstract—Natural Language Processing (NLP) is ...  Positive\n",
              "97   Abstract 98  ABSTRACT: After twenty years of disfavor, a te...  Negative\n",
              "98   Abstract 99  Text statistics are frequently used in stylome...   Neutral\n",
              "99  Abstract 100  We summarize our experience using FrameNet in ...  Negative\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlnruGU6Jdi1",
        "outputId": "75ef2104-a94f-4dd9-f405-749cb37fddc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pre-processing\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmdD2AkWZCmU",
        "outputId": "f80f8dc1-d042-44d8-9f04-7d48f2c119ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "source": [
        "# Special characters removal\n",
        "df['After noise removal'] = df['clean_text'].apply(lambda x: ''.join(re.sub(r\"[^a-zA-Z0-9]+\", ' ', charctr) for charctr in x ))\n",
        "# Punctuation removal\n",
        "df['Punctuation removal'] = df['After noise removal'].str.replace('[^\\w\\s]','')\n",
        "# Remove numbers\n",
        "df['Remove numbers'] = df['Punctuation removal'].str.replace('\\d+', '')\n",
        "# Stopwords removal\n",
        "stop_word = stopwords.words('english')\n",
        "df['Stopwords removal'] = df['Remove numbers'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_word))\n",
        "# Lower Casing\n",
        "df['Lower casing'] = df['Stopwords removal'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "# Lemmatization\n",
        "df['Lemmatization'] = df['Lower casing'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "df"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>After noise removal</th>\n",
              "      <th>Punctuation removal</th>\n",
              "      <th>Remove numbers</th>\n",
              "      <th>Stopwords removal</th>\n",
              "      <th>Lower casing</th>\n",
              "      <th>Lemmatization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abstract 1</td>\n",
              "      <td>describe a method for statistical modeling bas...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>describe a method for statistical modeling bas...</td>\n",
              "      <td>describe a method for statistical modeling bas...</td>\n",
              "      <td>describe a method for statistical modeling bas...</td>\n",
              "      <td>describe method statistical modeling based max...</td>\n",
              "      <td>describe method statistical modeling based max...</td>\n",
              "      <td>describe method statistical modeling based max...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abstract 2</td>\n",
              "      <td>Scaling conditional random fields for natural ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Scaling conditional random fields for natural ...</td>\n",
              "      <td>Scaling conditional random fields for natural ...</td>\n",
              "      <td>Scaling conditional random fields for natural ...</td>\n",
              "      <td>Scaling conditional random fields natural lang...</td>\n",
              "      <td>scaling conditional random fields natural lang...</td>\n",
              "      <td>scaling conditional random field natural langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abstract 3</td>\n",
              "      <td>The paper addresses the issue of cooperation b...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>The paper addresses the issue of cooperation b...</td>\n",
              "      <td>The paper addresses the issue of cooperation b...</td>\n",
              "      <td>The paper addresses the issue of cooperation b...</td>\n",
              "      <td>The paper addresses issue cooperation linguist...</td>\n",
              "      <td>the paper addresses issue cooperation linguist...</td>\n",
              "      <td>the paper address issue cooperation linguistic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abstract 4</td>\n",
              "      <td>In most natural language processing applicatio...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>In most natural language processing applicatio...</td>\n",
              "      <td>In most natural language processing applicatio...</td>\n",
              "      <td>In most natural language processing applicatio...</td>\n",
              "      <td>In natural language processing applications De...</td>\n",
              "      <td>in natural language processing applications de...</td>\n",
              "      <td>in natural language processing application des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abstract 5</td>\n",
              "      <td>We propose a unified neural network architectu...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>We propose a unified neural network architectu...</td>\n",
              "      <td>We propose a unified neural network architectu...</td>\n",
              "      <td>We propose a unified neural network architectu...</td>\n",
              "      <td>We propose unified neural network architecture...</td>\n",
              "      <td>we propose unified neural network architecture...</td>\n",
              "      <td>we propose unified neural network architecture...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Abstract 96</td>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>This paper presents a workbench built by Pribe...</td>\n",
              "      <td>This paper presents workbench built Priberam I...</td>\n",
              "      <td>this paper presents workbench built priberam i...</td>\n",
              "      <td>this paper present workbench built priberam in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Abstract 97</td>\n",
              "      <td>Abstract—Natural Language Processing (NLP) is ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Abstract Natural Language Processing  NLP  is ...</td>\n",
              "      <td>Abstract Natural Language Processing  NLP  is ...</td>\n",
              "      <td>Abstract Natural Language Processing  NLP  is ...</td>\n",
              "      <td>Abstract Natural Language Processing NLP effec...</td>\n",
              "      <td>abstract natural language processing nlp effec...</td>\n",
              "      <td>abstract natural language processing nlp effec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Abstract 98</td>\n",
              "      <td>ABSTRACT: After twenty years of disfavor, a te...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>ABSTRACT  After twenty years of disfavor  a te...</td>\n",
              "      <td>ABSTRACT  After twenty years of disfavor  a te...</td>\n",
              "      <td>ABSTRACT  After twenty years of disfavor  a te...</td>\n",
              "      <td>ABSTRACT After twenty years disfavor technolog...</td>\n",
              "      <td>abstract after twenty years disfavor technolog...</td>\n",
              "      <td>abstract after twenty year disfavor technology...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Abstract 99</td>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>Text statistics are frequently used in stylome...</td>\n",
              "      <td>Text statistics frequently used stylometry cry...</td>\n",
              "      <td>text statistics frequently used stylometry cry...</td>\n",
              "      <td>text statistic frequently used stylometry cryp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Abstract 100</td>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>We summarize our experience using FrameNet in ...</td>\n",
              "      <td>We summarize experience using FrameNet two rat...</td>\n",
              "      <td>we summarize experience using framenet two rat...</td>\n",
              "      <td>we summarize experience using framenet two rat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     document_id  ...                                      Lemmatization\n",
              "0     Abstract 1  ...  describe method statistical modeling based max...\n",
              "1     Abstract 2  ...  scaling conditional random field natural langu...\n",
              "2     Abstract 3  ...  the paper address issue cooperation linguistic...\n",
              "3     Abstract 4  ...  in natural language processing application des...\n",
              "4     Abstract 5  ...  we propose unified neural network architecture...\n",
              "..           ...  ...                                                ...\n",
              "95   Abstract 96  ...  this paper present workbench built priberam in...\n",
              "96   Abstract 97  ...  abstract natural language processing nlp effec...\n",
              "97   Abstract 98  ...  abstract after twenty year disfavor technology...\n",
              "98   Abstract 99  ...  text statistic frequently used stylometry cryp...\n",
              "99  Abstract 100  ...  we summarize experience using framenet two rat...\n",
              "\n",
              "[100 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6aAlLvGFA3"
      },
      "source": [
        "from textblob import TextBlob\n",
        "from collections import Counter"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaeRsVi51qQP",
        "outputId": "ed56005a-2ece-4236-e8f4-3052d578c774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentiment_text = []\n",
        "for i in df['Lemmatization']:\n",
        "  for term in i.split(' '):\n",
        "    if TextBlob(term).sentiment.polarity != 0:\n",
        "      sentiment_text.append(term)\n",
        "print(sentiment_text)\n",
        "word_count = Counter(sentiment_text)\n",
        "word_df = pd.DataFrame(list(word_count.most_common()), columns=['Terms', 'Freq'])\n",
        "word_df.index = list(range(1, len(word_count.most_common())+1))\n",
        "print(word_df)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natural', 'random', 'natural', 'natural', 'general', 'particular', 'natural', 'base', 'natural', 'more', 'natural', 'natural', 'subject', 'natural', 'broad', 'narrow', 'broad', 'natural', 'natural', 'natural', 'natural', 'unprocessed', 'natural', 'natural', 'natural', 'able', 'natural', 'natural', 'natural', 'natural', 'linguistic', 'directly', 'appropriate', 'natural', 'better', 'vague', 'precise', 'natural', 'natural', 'natural', 'lyric', 'significant', 'lyric', 'lyric', 'important', 'cultural', 'linguistic', 'direct', 'detailed', 'natural', 'high', 'interesting', 'new', 'natural', 'natural', 'naturally', 'natural', 'modern', 'limited', 'behind', 'limited', 'intelligent', 'natural', 'military', 'natural', 'developed', 'base', 'high', 'significant', 'far', 'particular', 'much', 'particular', 'natural', 'main', 'natural', 'naturally', 'linguistic', 'natural', 'kind', 'large', 'natural', 'contemporary', 'natural', 'natural', 'new', 'relevant', 'sound', 'developed', 'natural', 'natural', 'natural', 'broad', 'typical', 'good', 'linguistic', 'natural', 'important', 'first', 'natural', 'natural', 'better', 'natural', 'creative', 'many', 'complex', 'becoming', 'past', 'high', 'whole', 'whole', 'many', 'relevant', 'exact', 'general', 'special', 'subject', 'first', 'relevant', 'original', 'distinctly', 'developed', 'new', 'natural', 'linguistic', 'natural', 'natural', 'natural', 'little', 'early', 'natural', 'intelligent', 'natural', 'kind', 'successful', 'natural', 'natural', 'natural', 'natural', 'empirically', 'natural', 'sophisticated', 'natural', 'important', 'many', 'natural', 'usually', 'significant', 'higher', 'natural', 'natural', 'effectively', 'natural', 'effectively', 'natural', 'natural', 'natural', 'linguistic', 'natural', 'natural', 'effective', 'natural', 'natural', 'first', 'natural', 'mainly', 'new', 'main', 'natural', 'natural', 'typically', 'natural', 'large', 'artificial', 'many', 'foreign', 'extremely', 'popular', 'natural', 'due', 'powerful', 'unfortunately', 'good', 'fit', 'much', 'special', 'natural', 'single', 'particular', 'natural', 'effective', 'limited', 'particular', 'typically', 'easily', 'natural', 'single', 'developed', 'advanced', 'natural', 'natural', 'new', 'natural', 'natural', 'wide', 'natural', 'natural', 'artificial', 'natural', 'wide', 'most', 'unable', 'natural', 'natural', 'previous', 'approximate', 'useful', 'wide', 'natural', 'limited', 'far', 'natural', 'natural', 'able', 'single', 'new', 'stereotypical', 'action', 'natural', 'available', 'effectively', 'usefully', 'common', 'common', 'natural', 'widely', 'powerful', 'mod', 'many', 'natural', 'tedious', 'sophisticated', 'natural', 'significantly', 'general', 'past', 'natural', 'natural', 'linguistic', 'considerable', 'natural', 'effective', 'educational', 'natural', 'educational', 'effective', 'natural', 'frequently', 'developed', 'natural', 'natural']\n",
            "            Terms  Freq\n",
            "1         natural    96\n",
            "2      linguistic     7\n",
            "3             new     6\n",
            "4      particular     5\n",
            "5       developed     5\n",
            "..            ...   ...\n",
            "90            mod     1\n",
            "91        tedious     1\n",
            "92  significantly     1\n",
            "93   considerable     1\n",
            "94     frequently     1\n",
            "\n",
            "[94 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-LUPio3CBx_"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrvPuUMGNkww"
      },
      "source": [
        "def get_sentiments_counts(sentiments):\n",
        "  Negative_value = Positive_value = Neutral_value = 0\n",
        "  for polarity in sentiments:\n",
        "    if polarity < 0:\n",
        "      Negative_value = Negative_value + 1\n",
        "    elif polarity > 0:\n",
        "      Positive_value = Positive_value + 1\n",
        "    elif polarity == 0:\n",
        "      Neutral_value = Neutral_value + 1\n",
        "  return Negative_value, Positive_value, Neutral_value"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqJj7GE0aqNq"
      },
      "source": [
        "# TEXTBLOB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntVhg9TwCByA",
        "outputId": "972ac68f-84f1-458b-d9fb-3e5772c3bf9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('vader_lexicon')\n",
        "from textblob import TextBlob\n",
        "sentiments = []\n",
        "for i in df['Lemmatization']:\n",
        "  sentiments.append(TextBlob(i).sentiment.polarity)\n",
        "Negative_value, Positive_value, Neutral_value = get_sentiments_counts(sentiments)\n",
        "print('Number of Positives - {0}'.format(Positive_value))\n",
        "print('Number of Negatives - {0}'.format(Negative_value))\n",
        "print('Number of Neutrals - {0}'.format(Neutral_value))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "Number of Positives - 75\n",
            "Number of Negatives - 10\n",
            "Number of Neutrals - 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wourlYXKasmg"
      },
      "source": [
        "# VADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUcM_6sqQp-g",
        "outputId": "f07a82a4-3956-4c27-c58a-2af8bc965c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "sentiments = []\n",
        "for i in df['Lemmatization']:\n",
        "  sentiments.append(vader_analyzer.polarity_scores(i)['compound'])\n",
        "Negative_value, Positive_value, Neutral_value = get_sentiments_counts(sentiments)\n",
        "print('Number of Positives - {0}'.format(Positive_value))\n",
        "print('Number of Negatives - {0}'.format(Negative_value))\n",
        "print('Number of Neutrals - {0}'.format(Neutral_value))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Positives - 79\n",
            "Number of Negatives - 8\n",
            "Number of Neutrals - 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_QboSPNa_zk"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_ZPK0KTREs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noTzhN4xSe5a"
      },
      "source": [
        "def split_data(x_values, y_values):\n",
        "  return train_test_split(x_values, y_values, test_size=0.33)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8JsI4_3TSFJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyJFcA80TZCo"
      },
      "source": [
        "def get_vector():\n",
        "  return TfidfVectorizer(min_df = 5, max_df = 0.8, sublinear_tf = True, use_idf = True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdHOXPc3Tls7"
      },
      "source": [
        "TfidfVectorizer = get_vector()\n",
        "training_x, testing_x, training_y, testing_y = split_data(df['Lemmatization'], df['sentiment'])\n",
        "train_vectors = TfidfVectorizer.fit_transform(training_x)\n",
        "test_vectors = TfidfVectorizer.transform(testing_x)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XxYcBp4Ur6q"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NESU3RkXUzWk"
      },
      "source": [
        "def train_predict_model(train_vectors, test_vectors, training_y):\n",
        "  model = svm.SVC(kernel='linear')\n",
        "  model.fit(train_vectors, training_y)\n",
        "  return model.predict(test_vectors)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J4pZiQTVUr5"
      },
      "source": [
        "svm_report = classification_report(testing_y, train_predict_model(train_vectors, test_vectors, training_y), output_dict=True)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxAXvtngVi9G",
        "outputId": "2d0567aa-b1ce-4f87-d101-7636e2495476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('positive Report - ', svm_report['Positive'])\n",
        "print('Negative Report - ', svm_report['Negative'])\n",
        "print(\"Neutral Report - \", svm_report['Neutral'])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive Report -  {'precision': 0.6451612903225806, 'recall': 0.9523809523809523, 'f1-score': 0.7692307692307692, 'support': 21}\n",
            "Negative Report -  {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 7}\n",
            "Neutral Report -  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM9-YzB0V-Ns"
      },
      "source": [
        "def get_actual_sentiment_counts(sentiments):\n",
        "  Negative_value = Positive_value = Neutral_value = 0\n",
        "  for polarity in sentiments:\n",
        "    if polarity == 'Negative':\n",
        "      Negative_value = Negative_value + 1\n",
        "    elif polarity == 'Positive':\n",
        "      Positive_value = Positive_value + 1\n",
        "    elif polarity == 'Neutral':\n",
        "      Neutral_value = Neutral_value + 1\n",
        "  return Negative_value, Positive_value, Neutral_value"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUfqBvNvWgUm"
      },
      "source": [
        "Actual_Negative_Value, Actual_Positive_Value, Actual_Neutral_Value = get_actual_sentiment_counts(df['sentiment'])"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmuV5udpXNNS",
        "outputId": "8f536acf-9331-4fa8-c5f8-c45638b26ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Number of Actual Positives - {0}'.format(Actual_Positive_Value))\n",
        "print('Number of Actual Negatives - {0}'.format(Actual_Negative_Value))\n",
        "print('Number of Actual Neutrals - {0}'.format(Actual_Neutral_Value))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Actual Positives - 59\n",
            "Number of Actual Negatives - 25\n",
            "Number of Actual Neutrals - 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f26DRZV7dyyI"
      },
      "source": [
        "**Results:**\n",
        "\n",
        "Actual - \n",
        "\n",
        "Number of Actual Positives - 59\n",
        "\n",
        "Number of Actual Negatives - 25\n",
        "\n",
        "Number of Actual Neutrals - 16\n",
        "\n",
        "\n",
        "TextBlob - \n",
        "\n",
        "Number of Positives - 75\n",
        "\n",
        "Number of Negatives - 10\n",
        "\n",
        "Number of Neutrals - 15\n",
        "\n",
        "\n",
        "Vader -\n",
        "\n",
        "Number of Positives - 79\n",
        "\n",
        "Number of Negatives - 8\n",
        "\n",
        "Number of Neutrals - 13\n",
        "\n",
        "SVM - \n",
        "\n",
        "positive Report -  {'precision': 0.6451612903225806, 'recall': 0.9523809523809523, 'f1-score': 0.7692307692307692, 'support': 21}\n",
        "\n",
        "Negative Report -  {'precision': 1.0, 'recall': 0.14285714285714285, 'f1-score': 0.25, 'support': 7}\n",
        "\n",
        "Neutral Report -  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}\n",
        "\n",
        "\n",
        "From above results - \n",
        "\n",
        "On whole, we can say that SVM has better accuracy of polarities for the abstract texts.\n",
        "To conclude comparisons, we can say that SVM is better compared to TextBlob and Vader and among TextBlob and Vader, Textblob is better\n"
      ]
    }
  ]
}